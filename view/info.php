<h1>here you will find some basic info about what FDVR is</h1>
<section>
<h2>Origins of Full Dive Virtual Reality</h2>
<p>The term originated from a Japanese light novel anime series, Sword Art Online, written by Reki Kawahara in 2009. In the series, a Virtual Reality Massively Multiplayer Online Role-Playing Game (VRMMORPG) called Sword Art Online, or SAO, is released in the year 2022. 10,000 players don their “NerveGear” BMI(brain-computer interface) helmets and begin to play.
<br><br>
Players soon realize that the game developer has locked them into the game and that any attempt to logout or end the game will be fatal to their real-life bodies. The only way to exit the game, and to survive, is to successfully reach the 100th floor of the castle and defeat the final foe.
<br><br>
Not exactly the pitch you want to give investors, to be sure, but there are some good things there we can take away. First, the story popularized the concept of VRMMORPG. Gamers who weren’t thinking of engaging untold minions in gameplay suddenly started dreaming. Second, the concept of a helmet creating a non-invasive neural interface between man and machine whetted the appetite for those wanting a more seamless way to interact with computers. Not that the idea of BMIs was new, but seeing the concept demonstrated in such a rich storyline made the idea all the more tempting.</p>

<h2>Examples of Full Dive Virtual Reality in Use</h2>
<p>Back in the real world, real and exciting things are happening. Full dive virtual reality technology is rapidly stepping off the pages of science fiction and into the lab.</p>

<h3>Humble Beginnings</h3>
<p>Recent advances in technology can sometimes be appreciated more when contrasted with earlier successes and failures.
<br><br>
In 2013, Harvard University broke ground for FDVR advances by conducting a human- brain-to-mouse-brain experiment. In this experiment, researchers used an electroencephalogram (EEG) brain-brain-interface (BBI) to detect the thought patterns of a researcher. By focusing his thoughts, the researcher was able to control the movement of a rat’s tail. Not exactly the kind of action most serious gamers are looking for, but it marked an important turning point in BBI technology. For the first time, two brains communicated directly through a hardware interface.
<br><br>
There were two reasons why this experiment was noteworthy. Not only did it demonstrate that human thought could be correctly interpreted by computer and used to control a rat’s brain, but the experiment was non-invasive for both the researcher and the rat. While researchers around the world have been able to control rats’ brains through the use of implanted electrodes, this rat suffered no such indignity. Non-surgical focused ultrasound (FUS) was used to impart the control signals to the rat’s brain, a technology we will elaborate on shortly.</p>

<h3>The Paralyzed Walk</h3>
<p>
Fast-forward to 2015. Researchers at the University of California at Irvine also used an electroencephalogram machine to detect human thought. This time, however, those thoughts did not make it possible to control a rat’s tail, but to help a paraplegic man walk for the first time in five years. The man, who had suffered a spinal cord injury, walked nearly four meters with the assistance of the EEG device and advanced software.
<br><br>
The study involved placing electrodes on the patient’s head and on his legs. By detecting and interpreting signals from the man’s brain and sending those signals to his legs, the system bypassed the damaged spinal cord and allowed him to once again control the movement of his legs.
<br><br>
The experiment required the patient to undergo 19 weeks of training prior to taking his first step, but the encouraging results proved the concept was valid.
<br><br>
These two experiments may not be encouraging to those who had hoped for more, but consider this. Within two years, we have seen the technology advance from wiggling a rats tail to allowing a paralyzed person to actually walk across the floor. Such progress should be exciting, indeed, for anyone interested in full dive virtual reality development.</p>

<h2>Technologies involved in Full Dive Virtual Reality</h2>
<p>Full dive is a term that has been used by some game developers to imply that their games provide a more-immersive VR experience. By using advanced full-body motion sensors and high definition spacial audio, along with the VR headset, players do enjoy more immersive gameplay than ever before. But this is not true full dive.
<br><br>
Full dive, in the truest sense, goes beyond external viewers and sensors for user interaction and provides direct interaction between the user’s brain and the computer. Full dive is not so much full body immersion as it is full mind immersion.
<br><br>
Physical connections to the brain are not necessarily required, but there must be interpretation of the user’s thoughts by the computer, and — more importantly — the computer must be able to send sensory data directly into the user’s central nervous system. Full dive is, essentially, the ultimate goal of brain-to-computer interface research.
<br><br>
BCIs have been around, in various experimental stages, for years. What makes FDVR a new concept is that it has the added component of virtual reality. Regardless of whatever advancements in BCIs may have been made until now, VR is a game changer (no pun intended).
<br><br>
Within the scope of what full dive is, or can become, is the question of just how much interaction between user and machine is possible. Two levels of interaction are theoretically achievable: Mobile and Immobile.</p>

<h2>Mobile and Immobile Full Dive</h2>
<p>Mobile full dive, as the name suggests, involves the user physically moving his or her body with their movements being detected by external sensors, not unlike current VR technology. For lack of refined methods of detecting and interpreting thoughts, physical action provides the most reliable means of providing data to the computer. In order for the experience to be FDVR, the sensory data returned by the computer must be fed directly into the user’s brain or central nervous system; otherwise, we just have a conventional VR experience.
<br><br>
Immobile full dive, on the other hand, means just what it says: the user is immobile and the FD experience is entirely cerebral. No physical movement is necessary, as the computer can translate the user’s thoughts with adequate precision to control the program. While conventional VR gear could still be used — and probably will be for the foreseeable future, full dive will ultimately involve bypassing the user’s five senses by sending sights, sounds, smells, tastes, and tactile sensations directly into the brain.
<br><br>
In theory, a full full-dive experience would disable the user’s external sensory awareness, replacing it with virtual awareness for the duration of the HDVR session. Likewise, the user would have no need to move their body, as their thoughts would control their virtual bodies within VR space. There is, admittedly, a creep factor to being so totally immersed that one’s own physical body becomes obsolete. Some might even question whether we really want to go there. But, of course, we will.</p>

<h3>Government Help</h3>
<p>
Studies such as the Harvard experiment show exciting progress, there must be greater even advances in order for FD to become a reality. The U.S. Defense Advanced Research Project Agency (DARPA) may provide a key component.
<br><br>
DARPA plans to spend $60 million (USD) over the next four years to develop a high-resolution, wide-bandwidth intracranial electrode array for recording and stimulating brain activity. The DARPA Stentrode (stent and electrode) has been successfully tested in sheep and is injected into a blood vessel where it records and stimulates neural activity. Experiments with humans began in 2017.
<br><br>
The minimally invasive device may be the closest thing we have, yet, to a brain modem. And while the ultimate goal is to enjoy a full dive experience without the need for implants of any sort, the lessons learned by the Stentrode will help us to get there.
</p>

<h3>Electroencephalogram (EEG)</h3>
<p>
One secret to advancing any technology is to find what works and keep doing it. As we discussed, EEG systems were successful in the 2013 rat-tail experiment, and they were successful in the 2015 University of California at Irvine experiment where a paraplegic walked. As promising as the DARPA device may be, the non-invasive EEG holds, perhaps, greater promise for developers wishing to advance full dive technology.
<br><br>
EEG has already moved from the lab to commercial applications. One company, Emotive, has penetrated the market with 5-channel and 14-channel “neuroheadsets” and advanced EEG software. Emotive is developing applications for its products in the fields of “academic research, advertising and media, education and training, mobility, defense, communication, automotive and IoT (Internet of Things) development.”
<br><br>
Clearly, EEG is an excellent foundation upon which to advance full drive technology.</p>

<h3>Focused Ultrasound (FUS)</h3>
<p>
In terms of brain interfaces, focused ultrasound is a means of stimulating targeted regions of the brain by bombarding them with ultrasonic energy of a particular frequency and pressure level. In the case of the rat tail experiment, the motor cortex of the rat’s brain was stimulated with 350 KHz from a transducer placed on the rat’s head.
<br><br>
While FUS is primarily a therapeutic tool used by healthcare professionals for treating certain health conditions, Harvard’s out-of-the-box thinking adapted it for their brain interface. This is exactly the kind of creativity that will lead innovators to push full dive closer to reality.</p>

<h2>Full Dive Virtual Reality in Gaming</h2>
<p>
In the 2016 edition of this article, we stated, “To date, there are no TRUE full dive games…” And to be honest, no commercial-grade FD game was even on the horizon, nor the headset to control such a game.
<br><br>
That has all changed.
<br><br>
At SIGGRAPH 2017 in Los Angeles, Neurable debued the VR game Awakening. The game storyline goes like this: you are a child who has telekinetic powers and you are being held prisoner in a government lab. Robot prison guards are present prevent you from escaping your cell. The object of the game is to use your telekinetic abilities to select objects in the lab and to hurl them at the robot guards, knocking them out of commission. Defeat enough guards and you are free to escape.
<br><br>
Oh, yeah. And you control the game with your thoughts.
<br><br>
By simply focusing on whatever object you wish to weaponize, you cause that object to be thrown at the guards. The debut version used a modified HTC Vive headset. An array of sensors detect brainwave activity on the surface of the player’s scalp
<br><br>
If battling foes using only the power of your mind is on your bucket list, you might not have long to wait. Neurable is aggressively working with content developers and VR partners to bring their technology to market.
<br><br>
But wait… it gets even better.
<br><br>
Neurable is working on an SDK for Unity, so developers can build their own mind-controlled games. How cool is that?
<br><br>
Full dive virtual reality development isn’t all fun and games. Success requires a solid foundation in the very latest virtual reality technology, and the ability to transform complex theories into workable solutions. Pioneers in full dive development must go beyond adopting the latest technology; they must be able to do real science.</p>

<a target="_blank" href="https://www.linkedin.com/pulse/full-dive-virtual-reality-coming-soon-brain-near-you-aviram-eisenberg">source</a>
</section>

<section>
<h2>The full-body tracking and haptics approach</h2>
<p>This approach focuses not so much on making the VR user abandon their sense of the physical reality. Rather, it focuses on replicating the user – in terms of their body movement, looks, physical features and the like as close to the real world as possible.
<br><br>
At the same time, this approach focuses on providing haptic feedback to the VR user through high-resolution vibration and sensory-stimulation systems that stimulate the sensations of touching or interacting with virtual objects.
<br><br>
To be fair, currently this is the only consumer-facing category of virtual reality hardware and software. And while differing approaches exist at the mobile centric entry-level and the accuracy centric high-end, the general principle is still based on placing the user’s movements in a virtual world without overriding the user’s sense of the physical reality.</p>

<h2>The current state of full body tracking virtual reality</h2>
<p>
Tracking technology right now is split into two primary approaches:
<br><br>
an outside-in approach where cameras or sensors are mounted around a defined space and movement is tracked within that space; and
an inside-out approach where cameras or sensors are mounted on the VR headset and the space around the user is scanned and used as a reference for motion-tracking
Both approaches also rely on secondary and sometimes tertiary sources of tracking data in the form of controllers and optional additional trackers.
<br><br>
The Valve Index VR system is the prime example of a high-end outside-in VR tracking and positioning solution that relies on sensors mounted in the room (with a minimum of two), and the user being tracked at least through the headset as well as the handheld controllers.
<br><br>
You can also attach optional body trackers to your limbs, torso, hands or basically any other predefined body location so that the user can achieve a very close to one-to-one virtual reality tracking experience.
<br><br>
The professional grade Varjo VR-2 Pro, and the consumer-grade HP Reverb G2 as well as the hotly anticipated Deca Gear 1 VR Headset on the other hand are high-end inside-out tracking VR headsets with multi-camera solutions.
<br><br>
All this is nowhere near enough for full-dive VR tracking yet, but the technology is improving both in terms of quality as well as cost-effectiveness on an annual basis. Which bodes well at the very least for the eventual Ready Player One-esque drop-in, drop-out full dive VR of the nearer future.</p>

<h2>How haptic feedback suits are making full dive VR more plausible</h2>
<p>Haptic feedback is where the illusion of consumer-level VR headsets tends to completely break without relying on third party solutions. Thankfully, third party solutions do exist that offer full-body haptics for those willing to spend the necessary time as well as money for the set-up.
<br><br>
The most popular consumer-facing name in this category is bHaptics. bHaptics currently offers a range of haptic wearables from torso vests, to haptic VR head-cushions, through to similar attacheable haptic devices for one’s arms, feet and hands.
<br><br>
While bHaptics’s solutions are compelling, compare them to something like the pro-grade Teslasuit and the bHaptic’s offerings pale in comparison.
<br><br>
Where bHaptic’s offerings rely on vibration motors and strictly provide haptic feedback in these terms, the teslasuit uses electro-therapy based muscular stimulation and can simulate sensations of heat, shock, wind, cold in addition to vibration-based impacts.
<br><br>
The Teslasuit is also a full-body wearable suit. But given its price-point of over $2500 as well as its intended use-cases of training and rehabilitation, software support for the Teslasuit outside of its specialized training and medical rehabilitation applications is obviously going to be hit or miss.
<br><br>
So, the state of haptics is quite a bit different than that for tracking and general VR displays in the sense that we have very advanced haptic systems currently available.
<br><br>
However, the prices for a convincing haptics VR solution are still quite high, and the software support for all but the most mainstream of the technology is lacking.</p>

<h2>The “Nerve-Gear” brain-computer interface approach</h2>
<p>When we think of full-dive VR, we think of Nerve-Gear or the Matrix-style dropping-in to a virtual world and completely losing sense of the physical world till we drop out.
<br><br>
No matter how advanced full-body tracking gets and no matter how well the haptics and other sensory stimulations get, as long as we can also feel and sense the physical world around us, it arguably is not a true full-dive experience.
<br><br>
And that is why there exists the other, much moreambitious approach to virtual reality: the brain-computer interface (BCI) approach.</p>

<h2>The viability of Non-invasive BCI for VR</h2>
<p>In principle, brain-computer interfacing is any means by which one can control or interface with a machine directly through the power of the electrical impulse of the body.
<br><br>
There have been many novelty toys based on this concept. All these devices usually come with an EEG (electroencephalogram) monitor built-in to monitor brain activity and translate it into some form of movement or computer function, this is known as “non-invasive” BCI.
<br><br>
While work in the non-invasive BCI space far surpasses efforts in other types of BCI – there is currently even an EEG-based VR game released for the HTC Vive that replaces the head cushion with an EEG monitor. Other companies such as Emotiv provide EEG-based BCI solutions for research as well as business purposes right now.
<br><br>
The problem with the non-invasive BCI approach lies in that we know very little about how the human brain functions on a common basis, let alone how it changes from person to person to account for age, disease, gender, upbringing, trauma and many other factors.</p>

<h2>Semi-invasive and invasive brain-computer interfacing</h2>
<p>Let’s face it, the 10-year future of full dive VR is not looking so hot. Enter the other two research areas in BCI: semi-invasive and invasive Brain-computer interfacing.
<br><br>
Elon Musk recently demonstrated an example of a semi-invasive brain-computer interface in the form of Neuralink. A small coin-sized chip that sits in a person’s skull, with electrodes surgically implanted on the surface of the brain that would allow for the ability to read brain activity as well as to write code to dictate or modify brain activity.
<br><br>
Musk has said that while the initial goal is to overcome brain and spine-related injuries by providing a neural link that overrides spinal injury for example, future implementations could possibly allow a person to backup and restore one’s own memories as well as to interface with the human brain potentially the same as any other computer.
<br><br>
With that said, however, even Musk admitted that Neuralink’s primary goal is to research the potential of such semi-invasive approaches for furthering brain-computer interface technology.
<br><br>
In addition to Neuralink, another research startup called Kernel has set out to do primarily the same thing as Neuralink and actually has been researching invasive BCI for longer than Neuralink as well.
<br><br>
Similary, DARPA currently is funding a so-called Stentrode (a portmanteau of Stent and Electrode) project worth $60 million to develop an intracranial electrode array for recording and stimulating brain activity.
<br><br>
While invasive BCI will possibly never become the standard for something like full dive VR, the breakthroughs in these researches would probably go a long way in building a non-invasive Nerve Gear style BCI for eventual commercial use.
<br><br>
BCI most certainly promises the definitive full-dive VR experience one day, and with breakthroughs happening on almost a monthly basis in this field it is hard to pinpoint how far off we actually are but it is tantalizing to think that it may not be too far off into the future.</p>

<h2>Other technologies that could potentially help reach the full dive VR dream</h2>
<p>Aside from improvements to haptics, graphics, display, smell and sound. There are a number of exciting technologies and areas of scientific study being worked on today that could truly help complete the full-dive VR dream.
<br><br>
The foremost of these is definitely electronic skin or e-skin. E-skin refers to wearable electronics and sensors that are so flexible and lightweight that they can be added to clothing or even be integrated inside it without any noticeable difference by the user.
<br><br>
Xenoma currently makes a line of e-skin products primarily targeting medical applications and monitoring needs. These could easily be modified and retrofitted for full-dive VR needs where the software could keep track of all sorts of body metrics and physical activity of the user and possibly even adjust the VR scenario accordingly.
<br><br>
The work in neuroscience to achieve a detailed and complete mapping of the human brain via brain scans would also go a long way in helping achieve both better brain-computer interfaces as well as to help in design VR worlds that are much more immersive and in tune with what our brains perceive as real. Another essential field of study for full-dive VR is that of neuro-prosthetics.
<br><br>
Neuro-prosthetics technology focuses on translating the movement related signals from the brain – from the motor cortex of the brain specifically – and then relay those signals to a computer that would then be able to translate them to motion in either a robotic limb, or through electrodes implanted in the muscles in the person’s limb.
<br><br>
Understanding the motor cortex signals would be essential to allow a user in full-dive VR to move naturally and completely.
<br><br>
In a semi-conscious state of full dive, it would be paramount to override to make sure these motor cortex signals do not translate into real world motion that could inadvertently hurt the VR user or any other person around them.
<br><br>
Another neuro-prosthetic technology that comes to mind is cochlear implants, a type of device that uses electronic signals to enable the deaf to hear sound. It does so by tapping into the cochlear nerve.
<br><br>
It may be silly to suggest that these technologies will be reengineered into VR devices. That is a stretch to say the least. But it’s an idea. And it is theoretically possible.</p>

<h2>Possible limitations of full dive VR</h2>
<p>While it is fun to think that full-dive VR would be the be-all, end-all of immersive technology, it is important to note that like all technology before it, full-dive VR would not be without limitations.
<br><br>
We really should not expect commercially available full-dive VR to come cheap for one. Even when it eventually becomes a reality. Full-dive VR would probably be as expensive as businesses could sell it for initially.
<br><br>
Even though we talk about total immersion when it comes to full dive, it is important to note that even in total escape from the real world, we still would not be able to escape from commercial interests of companies selling these experiences.
<br><br>
It should be remembered that the entire full-dive VR world would be software-based. A poorly designed, or even a well-designed but rushed VR world would no doubt be filled with hilarious and perhaps even experience breaking bugs.<br><br>
And lastly, it should be of note, that even spending too long a time in normal virtual reality is said to have adverse effects on a person’s mental faculties. True full-dive VR would probably then come with health-related caveats especially if it would be in the style of Sword Art Online where the user is essentially in a half-sleep state with no actual muscle movement for prolonged periods of time.</p>

<h2>How long till full dive VR become a real-world reality</h2>
<p>Will we see full dive VR devices in the coming decade? Probably not. Not to the degree we’ve come to expect anyways. In the next 20 years? Maybe.
<br><br>
Although it is a possibility of future technology that feels overdue at this point. But the truth is that while human imagination has enabled us to dream up what such an experience could actually provide, the technology to achieve full-dive VR still has some catching up to do.
<br><br>
Even when technology does catch up, which may very well be in the next 30 to a 100-years, there will be some bioethical concerns to deal with. Which is the real sticking point holding the technology back as a viable business proposition.
<br><br>
Whenever that finally happens though, a revolution will be upon us. One enticing enough for the world to fully dive in to.</p>

<a target="_blank" href="https://3drific.com/is-full-dive-vr-achievable-in-the-next-10-years/">source</a>
<br><br>
</section>

<!--  to make it dynamic i could put the sections into my database  
foreach ($info_paragraphs as $paragraph)
{
	
	<section>

	echo $paragraph; 

	</section>
	
}
-->
